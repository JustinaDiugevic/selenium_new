# 🛒 Selenium Web Scraper for E-commerce Product Data

This project automates data collection from **e-commerce websites** (online stores) using **Selenium** in Python.  
It extracts product details such as **name, price, rating, and URL** from dynamic pages and exports them into a structured CSV file for further analysis.

It demonstrates my ability to:
- Automate repetitive data collection tasks,
- Extract structured information from dynamic web pages,
- Clean and export data for further analysis or visualization (Power BI, Excel, etc.).

---

## 🧰 Tools and Libraries

- **Python 3.x**
- **Selenium**
- **Pandas**
- **BeautifulSoup4**
- **ChromeDriver**

---

## 🏗️ Project Structure

selenium_new/
│
├── src/
│ └── scraper.py # main script for data scraping
│
├── data/
│ └── example_output.csv # sample scraped data
│
├── requirements.txt # dependencies
└── README.md # project documentation

yaml
Copy code

---

## ▶️ How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/JustinaDiugevic/selenium_new.git
   cd selenium_new
Install dependencies

bash
Copy code
pip install -r requirements.txt
Run the scraper

bash
Copy code
python src/scraper.py
Find your results

The collected data will be saved to:
data/example_output.csv

💡 Example Output
Product	Price	Rating	URL
Cotton T-Shirt	€19.99	⭐⭐⭐⭐	link
Sneakers	€49.99	⭐⭐⭐	link
Sports Bag	€29.90	⭐⭐⭐⭐½	link

(Replace this table with 3–5 real rows from your scraped dataset.)

📊 Use Case
This scraper can be used to:

Collect product data for market research or price comparison,

Monitor price trends and availability,

Prepare structured datasets for data analysis or Power BI dashboards,

Automate manual product tracking for short-term analysis projects.

🧠 What I Learned
Setting up and running Selenium WebDriver efficiently,

Using XPath and CSS selectors to locate page elements,

Managing wait times and avoiding timeouts for dynamic content,

Exporting clean datasets in CSV format for analysis.

📸 Screenshots
Add screenshots here to make the project more visual:

Screenshot of the website being scraped (if allowed).

Screenshot of the scraper running (terminal output).

Screenshot or snippet of the output CSV.

Example:

🧩 Next Steps / Possible Improvements
Add a scheduler to scrape data automatically (daily / weekly),

Integrate an email notification when new items or price drops appear,

Add a Jupyter Notebook to analyze the collected data (charts, summaries).

💬 Case Study Example
“A client wanted to monitor daily product prices from several online stores.
I built this Selenium scraper that collects, cleans, and saves product data automatically.
The output was integrated into a Power BI dashboard to visualize price changes and stock availability.”

📫 Contact
If you’d like to collaborate or need help with a similar web automation project, feel free to reach out:

LinkedIn: https://www.linkedin.com/in/justina-di%C5%ABgevi%C4%8D/


GitHub: https://github.com/JustinaDiugevic

🏁 Summary
This project highlights:

My ability to automate data extraction using Selenium,

My skills in Python scripting and data organization,

How I can deliver real-world automation solutions for freelance or short-term clients.

⭐ If you find this project interesting, feel free to star the repository!
👩‍💻 Created by Justina Diugevič — Junior Data Analyst



